# Model Predictions and SHAP Explanations

This document explains how predictions are generated by each model in the Titanic XAI application, how SHAP values relate to those predictions, and the mathematical conversions between different representation spaces.

## Table of Contents

- [Overview](#overview)
- [Decision Tree Predictions](#decision-tree-predictions)
- [XGBoost Predictions](#xgboost-predictions)
- [SHAP Values and Explanations](#shap-values-and-explanations)
- [Mathematical Conversions](#mathematical-conversions)
- [Display Formats](#display-formats)
- [Complete Example](#complete-example)

---

## Overview

The Titanic XAI application uses two different machine learning models:
- **Decision Tree**: A single interpretable tree
- **XGBoost**: An ensemble of gradient-boosted trees

These models have **fundamentally different prediction mechanisms** and output different types of values, which are then converted to survival rate percentages for user display.

---

## Decision Tree Predictions

### How It Works

Decision trees predict by counting samples in leaf nodes and calculating proportions.

**Source Code**: `backend/models/decision_tree.py:121`

```python
probability = class_1_count / samples if samples > 0 else 0
```

### Prediction Process

1. **Route passenger through tree**: Follow decision rules until reaching a leaf node
2. **Count samples in leaf**:
   - `class_0_count = 10` (died)
   - `class_1_count = 50` (survived)
   - `samples = 60` (total)
3. **Calculate survival probability**:
   ```
   probability = 50 / 60 = 0.833
   ```

### Native Output

- **Type**: Direct probability (survival rate)
- **Range**: 0.0 to 1.0
- **Space**: Probability space
- **Conversion needed**: None (already a probability)

### Display

```
Frontend: 0.833 → 83% survival rate
```

**File**: `frontend/src/components/visualizations/DecisionTreeViz.jsx:527-536`

```javascript
const survivalRate = (d.data.probability * 100).toFixed(1)
// Displays: "Survival Rate: 83.3%"
```

---

## XGBoost Predictions

### How It Works

XGBoost is an ensemble of decision trees. Each tree outputs a continuous value, and these values are summed to produce a **raw score in log-odds space**.

**Source Code**: `backend/models/xgboost_model.py:85-94`

```python
prediction = model.predict(input_data)[0]           # Binary class: 0 or 1
probabilities = model.predict_proba(input_data)[0]  # [died_prob, survived_prob]
```

### Prediction Process

1. **XGBoost ensemble output**: Sum of all tree predictions → log-odds
2. **Apply sigmoid function**: Convert log-odds → probability
3. **Threshold at 0.5**: Convert probability → binary class

```
Tree ensemble → log-odds (4.477) → sigmoid → probability (0.989) → class (1)
```

### Native Output

- **Type**: Log-odds (logit)
- **Range**: -∞ to +∞
- **Space**: Log-odds space
- **Conversion needed**: Sigmoid transformation

### Display

```
Backend:  log-odds = 4.477
          ↓ sigmoid
          probability = 1/(1 + e^(-4.477)) = 0.989
Frontend: 0.989 → 99% survival rate
```

**File**: `frontend/src/components/PredictionCard.jsx:60-89`

```javascript
const survivalProbability = Math.round(prediction.probability_survived * 100)
// Displays: "99%"
```

---

## SHAP Values and Explanations

### What Are SHAP Values?

SHAP (SHapley Additive exPlanations) values decompose a prediction into contributions from each feature. They answer: **"How much did each feature contribute to moving the prediction from the average to this specific value?"**

### The Core Formula

```
Final Prediction = Base Value + Sum of SHAP Values
```

**Source Code**: `backend/models/xgboost_model.py:131`

```python
final_prediction = float(base_value + np.sum(shap_values_individual))
```

### Components

| Component | Mathematical Meaning | Example Value |
|-----------|---------------------|---------------|
| **Base Value** | Population average prediction (expected value) | -0.386 |
| **SHAP Values** | Individual feature contributions (+ or -) | [+2.5, +1.2, -0.3, +0.1] |
| **Final Prediction** | Base + sum of SHAP values (log-odds) | 4.477 |

### Why Log-Odds?

SHAP values must be **additive**. This property only holds in log-odds space, not probability space.

```
✅ Log-odds:   -0.386 + 4.863 = 4.477  (works perfectly)
❌ Probability: 0.405 + ??? ≠ 0.989    (can't just add probabilities!)
```

### SHAP Calculation

**Source Code**: `backend/models/xgboost_model.py:121-129`

```python
# Create SHAP explainer
explainer = shap.TreeExplainer(xgb_model)

# Get SHAP values for a specific prediction
shap_values_individual = explainer.shap_values(input_data)[0]
expected_val = explainer.expected_value

# Base value (expected value from training data)
base_value = float(expected_val)
```

### Feature Contributions

Each SHAP value shows how much a feature pushes the prediction:
- **Positive SHAP value**: Feature increases survival probability
- **Negative SHAP value**: Feature decreases survival probability
- **Zero SHAP value**: Feature has no effect on this prediction

Example:
```python
shap_values = {
    'sex': +2.456,    # Being female strongly increases survival
    'pclass': +1.234, # First class increases survival
    'age': -0.342,    # Age slightly decreases survival
    'fare': +0.089    # Fare slightly increases survival
}
```

---

## Mathematical Conversions

### Sigmoid Function

The sigmoid function converts log-odds to probabilities:

```
probability = 1 / (1 + e^(-log_odds))
```

**JavaScript Implementation**: `frontend/src/components/visualizations/SHAPWaterfall.jsx:25-28`

```javascript
const logOddsToPercent = (logOdds) => {
  const probability = 1 / (1 + Math.exp(-logOdds))
  return Math.round(probability * 100)
}
```

### Conversion Examples

| Log-Odds | Calculation | Probability | Percentage |
|----------|-------------|-------------|------------|
| -0.386 | 1/(1 + e^(0.386)) | 0.405 | 40% |
| 0.000 | 1/(1 + e^0) | 0.500 | 50% |
| 1.000 | 1/(1 + e^(-1)) | 0.731 | 73% |
| 2.000 | 1/(1 + e^(-2)) | 0.881 | 88% |
| 4.477 | 1/(1 + e^(-4.477)) | 0.989 | 99% |

### Interpretation

- **Log-odds = 0**: Equal chance of survival/death (50%)
- **Log-odds > 0**: More likely to survive
- **Log-odds < 0**: More likely to die
- **Larger magnitude**: Stronger prediction confidence

---

## Display Formats

### Decision Tree Visualization

**File**: `frontend/src/components/visualizations/DecisionTreeViz.jsx`

```javascript
// Hover tooltip (line 527-536)
const survivalRate = (d.data.probability * 100).toFixed(1)
// Shows: "Survival Rate: 92.0%"

// Leaf node label (line 579-584)
const label = predicted_class === 1 ? "Survived" : "Died"
```

**Format**: Percentage with 1 decimal place

### XGBoost Prediction Card

**File**: `frontend/src/components/PredictionCard.jsx`

```javascript
// Main display (line 61)
const survivalProbability = Math.round(prediction.probability_survived * 100)
// Shows: "86%"

// Secondary display (line 99-104)
const deathProbability = Math.round(prediction.probability_died * 100)
// Shows: "Death Probability: 14%"
```

**Format**: Rounded integer percentage

### SHAP Waterfall Chart

**File**: `frontend/src/components/visualizations/SHAPWaterfall.jsx`

```javascript
// Chart title (line 110)
`Base Value: ${baseValue.toFixed(3)} (${basePercent}%) →
 Final Prediction: ${finalPrediction.toFixed(3)} (${finalPercent}%)`
// Shows: "Base Value: -0.386 (40%) → Final Prediction: 4.477 (99%)"

// Bottom explanation (line 309)
"Values shown in log-odds; survival rates in parentheses"
```

**Format**: Log-odds with 3 decimals, survival rate in parentheses

### Chat Comparison View

**File**: `frontend/src/components/SinglePredictionCard.jsx`

```javascript
// Both models displayed identically (lines 59, 99-101, 118-120)
const formatPercentage = (prob) => `${Math.round(prob * 100)}%`
// Shows: "84%" vs "86%"
```

**Format**: Rounded integer percentage for both models

---

## Complete Example

### Scenario

**Passenger**: 30-year-old female, 1st class, £84 fare

### Decision Tree

```
Input: {sex: 0, pclass: 1, age: 30, fare: 84}
  ↓ Route through tree
Leaf node: 50 survived, 10 died (60 total samples)
  ↓ Calculate proportion
Probability: 50/60 = 0.833
  ↓ Convert to percentage
Display: 83% survival rate
```

### XGBoost (Native Prediction)

```
Input: {sex: 0, pclass: 1, age: 30, fare: 84}
  ↓ XGBoost ensemble
Log-odds: 1.568
  ↓ Apply sigmoid: 1/(1 + e^(-1.568))
Probability: 0.827
  ↓ Convert to percentage
Display: 83% survival rate
```

### XGBoost (SHAP Explanation)

```
Base Value (population average):
  log-odds: -0.386
  survival rate: sigmoid(-0.386) = 40%

SHAP Contributions:
  sex (female):     +2.456
  pclass (1st):     +1.234
  age (30):         -0.342
  fare (£84):       +0.089
  ─────────────────────────
  Sum:              +3.437

Final Prediction:
  log-odds: -0.386 + 3.437 = 3.051
  survival rate: sigmoid(3.051) = 95%

Display: "Base Value: -0.386 (40%) → Final Prediction: 3.051 (95%)"
```

### Waterfall Visualization

The SHAP waterfall chart shows this progression visually:

```
Step 0 (Base):      ████  Position: -0.386 (40% survival)
Step 1 (sex):       ████████████████████ +2.456 → 2.070 (89%)
Step 2 (pclass):    ████████ +1.234 → 3.304 (96%)
Step 3 (age):       ██ -0.342 → 2.962 (95%)
Step 4 (fare):      █ +0.089 → 3.051 (95%)

Final: 3.051 log-odds = 95% survival
```

Each bar shows:
- **Green bars**: Positive contributions (increase survival)
- **Orange bars**: Negative contributions (decrease survival)
- **Bar position**: Cumulative sum at that step
- **Bar height**: Magnitude of SHAP contribution

---

## Key Takeaways

### Model Outputs

| Model | Native Output | Range | Conversion | Display |
|-------|---------------|-------|------------|---------|
| Decision Tree | Probability | 0.0 - 1.0 | None needed | 0.833 → "83.3%" |
| XGBoost | Log-odds | -∞ to +∞ | Sigmoid → probability | 1.568 → 0.827 → "83%" |

### SHAP Values

- Work in **log-odds space** for XGBoost
- Are **additive**: Base + Sum(SHAP) = Final Prediction
- Explain the **raw model output** (log-odds), not the probability
- Must be **converted to probabilities** for user interpretation

### Display Philosophy

- **User-facing predictions**: Always shown as **survival rate percentages** (0-100%)
- **SHAP explanations**: Show **log-odds** (technical accuracy) with **percentages in parentheses** (user understanding)
- **Both models**: Ultimately communicate the same information - survival probability

---

## References

### Backend Files

- `backend/models/decision_tree.py`: Decision tree implementation and prediction
- `backend/models/xgboost_model.py`: XGBoost implementation and SHAP calculation

### Frontend Files

- `frontend/src/components/PredictionCard.jsx`: XGBoost prediction display
- `frontend/src/components/visualizations/DecisionTreeViz.jsx`: Decision tree visualization
- `frontend/src/components/visualizations/SHAPWaterfall.jsx`: SHAP waterfall chart
- `frontend/src/components/SinglePredictionCard.jsx`: Model comparison display

### Mathematical References

- [Sigmoid Function](https://en.wikipedia.org/wiki/Sigmoid_function)
- [Log-odds](https://en.wikipedia.org/wiki/Logit)
- [SHAP (SHapley Additive exPlanations)](https://github.com/slundberg/shap)
